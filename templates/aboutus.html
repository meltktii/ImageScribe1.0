<!DOCTYPE html>
<html lang="en">
<link rel="icon" href="/static/logo.png/">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ImageScribe</title>
    <!-- Link to the external CSS file -->
    <link rel="stylesheet" href="{{ url_for('static', filename='aboutstyle.css') }}">
</head>
<body>
    <div class="button">
        <button class="btn1" onclick="window.location.href='/home'"><b>Home</b></button>
        <button class="btn2" onclick="window.location.href='/contact'"><b>Contacts</b></button>
        <button class="btn3" onclick="window.location.href='/aboutus'"><b>About Us</b></button>
    </div>

    <div id="horizontal-line"></div>

    <h1><b>ImageScribe</b></h1>
    <p>ImageScribe specializes in developing advanced deep learning-based solutions for automatic image captioning and
        description synthesis.
        Our major aim is to create intelligent systems that can successfully analyze and describe digital images while
        also fulfilling the needs of visually impaired individuals, increasing image search capabilities, and enhancing
        content understanding across a wide range of applications.</p>
        <p>The goal of this research is to create AI models for
        automatically producing textual descriptions for photographs in educational resources.
        This entails developing a system that can generate accurate and contextually appropriate descriptions for images found in
        textbooks, online courses, and other educational materials.Techniques include training Convolutional Neural
        Networks (CNNs) and Recurrent Neural Networks (RNNs) to grasp a wide range of instructional imagery from
        science, history, and geography.</p>
        <p>The assignment entails creating descriptions that improve the learning
        experience by including thorough explanations and contextual information about the photos. The study will also
        examine issues linked to various types and formats of instructional pictures in order to ensure robustness and
        accuracy in caption production. We intend to solve current market challenges by integrating powerful CNNs and
        RNNs to give precise, contextually relevant captions for complex circumstances.</p>
</body>
</html>
